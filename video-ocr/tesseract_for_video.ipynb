{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tesseract-for-video",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVWDaySeDi6a"
      },
      "source": [
        "## Imports & Installs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naWrFLfKE2ox"
      },
      "source": [
        "# Mount Drive & navigate to folder\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# You may need to change the line below to the location of the _AMPPD folder if \n",
        "# the _AMPPD folder isn't in the 'root' of your Drive ('My Drive')\n",
        "%cd '/content/drive/My Drive/_AMPPD TEAM SHARED FOLDER'\n",
        "\n",
        "%cd 'MGMs/Video OCR/Tesseract'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4fHOAFye8Z0"
      },
      "source": [
        "# Install tesseract\n",
        "!pip install pytesseract\n",
        "!sudo apt install tesseract-ocr\n",
        "!sudo apt install libtesseract-dev"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8P9eA80Dehl"
      },
      "source": [
        "# Checking tesseract version\n",
        "import pytesseract\n",
        "pytesseract.get_tesseract_version()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KK8VGLWi_Ug"
      },
      "source": [
        "# Python imports\n",
        "try:\n",
        "    from PIL import Image\n",
        "except ImportError:\n",
        "    import Image\n",
        "import pytesseract\n",
        "import os\n",
        "import json\n",
        "\n",
        "from datetime import timedelta\n",
        "from decimal import Decimal"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8a5VH2kDQpF_"
      },
      "source": [
        "# sample tesseract output\n",
        "from pytesseract import Output\n",
        "result = pytesseract.image_to_data(Image.open(\"temp/little500.mp4/frame_00001.jpg\"), output_type=Output.DICT) \n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gLY2DNREDeR"
      },
      "source": [
        "## Generate samples for testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5w1QShTGOaW"
      },
      "source": [
        "# Make samples from full videos for testing\n",
        "\n",
        "#!ffmpeg -ss 00:8:00.0 -i \"../../../media/IU Archives/Little 500 Variety Video/access/Little 500 Variety Video.mp4\" -c copy -t 00:05:00.0 \"little500.mp4\"\n",
        "#!ffmpeg -ss 00:00:00.0 -i \"../Day_of_desperation-first_10min.mp4\" -c copy -t 00:05:00.0 \"dod.mp4\"\n",
        "#!ffmpeg -ss 00:15:00.0 -i \"../West_side_story-first_30min.mp4\" -c copy -t 00:05:00.0 \"wss.mp4\"\n",
        "        \n",
        "samples = [{\"filename\":\"little500.mp4\", \"sample_start\":480, \"sample_duration\":300}, \n",
        "           {\"filename\":\"dod.mp4\", \"sample_start\":0, \"sample_duration\":300}, \n",
        "           {\"filename\":\"wss.mp4\", \"sample_start\":900, \"sample_duration\":300},\n",
        "           {\"filename\":\"little_500_end_credits.mp4\", \"sample_start\":1644, \"sample_duration\":52},\n",
        "           {\"filename\":\"astin_patten_transparencies.mp4\", \"sample_start\":2047, \"sample_duration\":472}]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWWiFJK0Dnzl"
      },
      "source": [
        "## Save frames\n",
        "\n",
        "For each video in the samples, save 2 frames every second as `.jpg` in a temporary directory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-FR2IIXAYsR"
      },
      "source": [
        "#clear old images\n",
        "!rm -rf \"temp\"/*\n",
        "\n",
        "# Save 2 frames a second\n",
        "# Could probably do this with cv2 as well. Not sure how to save every nth frame\n",
        "# https://www.geeksforgeeks.org/python-program-extract-frames-using-opencv/\n",
        "import time\n",
        "\n",
        "for s in samples:\n",
        "  start = time.time()\n",
        "  name = s[\"filename\"]\n",
        "  !mkdir \"temp/{name}\"\n",
        "  !ffmpeg -i \"../Clips/{name}\" -an -vf fps=2 \"temp/{name}/frame_%05d.jpg\" \n",
        "  print(\"Finished \" + name + \" in \" + str(time.time()-start) + \"s\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CN5xBN3DeJ8"
      },
      "source": [
        "## Utility Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SG3sszCCM1b4"
      },
      "source": [
        "# UTIL FUNCTIONS\n",
        "def getDimensions(path):\n",
        "  dim = !ffprobe -v error -select_streams v:0 -show_entries stream=width,height -of csv=s=x:p=0 \"{path}\"\n",
        "  print(path)\n",
        "  print(dim)\n",
        "  return dim[0].split(\"x\")\n",
        "\n",
        "\n",
        "def getFramerate(path):\n",
        "  fr = !ffprobe -v error -select_streams v:0 -show_entries stream=r_frame_rate -of default=nokey=1:noprint_wrappers=1  \"{path}\"\n",
        "  print(int(fr[0].split('/')[0]))\n",
        "  return int(fr[0].split('/')[0])\n",
        "\n",
        "def getNumFrames(path):\n",
        "  nf = !ffprobe -v error -select_streams v:0 -show_entries stream=nb_frames -of default=nokey=1:noprint_wrappers=1 \"{path}\"\n",
        "  print(int(nf[0]))\n",
        "  return int(nf[0])\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uoiSVAueDW4X"
      },
      "source": [
        "## Run Tesseract & get JSON outputs\n",
        "\n",
        "For every sample, run Tesseract OCR on every saved frame. Write the results to a JSON file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EnxT79ysHVS"
      },
      "source": [
        "# RUN TESSERACT & GET JSON OUTPUT\n",
        "from pytesseract import Output\n",
        "import time\n",
        "\n",
        "for s in samples: # for all our sample videos\n",
        "  \n",
        "  print(\"Running: \" + s[\"filename\"])\n",
        "  script_start = time.time()\n",
        "\n",
        "  directory = \"temp/\" + s[\"filename\"]\n",
        "\n",
        "  output_name = s[\"filename\"] + \"-ocr.json\" # name an ouput file for our final json\n",
        "\n",
        "  # Get some stats on the video\n",
        "  dim = getDimensions(\"../Clips/\"+s['filename'])\n",
        "  framerate = getFramerate(\"../Clips/\"+s['filename'])\n",
        "  numFrames = getNumFrames(\"../Clips/\"+s['filename'])\n",
        "\n",
        "  # Establish the basic fields of our output schema\n",
        "  output = {\n",
        "      \"media\": {\n",
        "          \"filename\": s[\"filename\"],\n",
        "          \"duration\": str(s[\"sample_duration\"]),\n",
        "          \"framerate\": framerate,\n",
        "          \"numFrames\": numFrames,\n",
        "          \"resolution\": {\n",
        "              \"width\": int(dim[0]),\n",
        "              \"height\": int(dim[1])\n",
        "          }\n",
        "          \n",
        "      },\n",
        "      \"frames\": []\n",
        "  }\n",
        "\n",
        "  start_time = s[\"sample_start\"] #adjust for our samples not starting at 0:00\n",
        "  for num, img in enumerate(sorted(os.listdir(directory))): #for every saved frame\n",
        "      start_time =+ (.5*num) # Add multiples of 1/2 to the start time because we saved 2 frames a second\n",
        "      frame = {\n",
        "            \"start\": str(start_time),\n",
        "            \"boundingBoxes\": []\n",
        "        }\n",
        "      \n",
        "      #Run OCR\n",
        "      result = pytesseract.image_to_data(Image.open(directory+\"/\"+img), output_type=Output.DICT) \n",
        "      \n",
        "      #For every result, make a box & add it to the list of boxes for this frame\n",
        "      for i in range(len(result[\"text\"])): \n",
        "        if result[\"text\"][i].strip(): #if the text isn't empty/whitespace\n",
        "          box = {\n",
        "              \"text\": result[\"text\"][i],\n",
        "              \"score\": {\n",
        "                  \"type\":\"confidence\",\n",
        "                  \"scoreValue\": result[\"conf\"][i]\n",
        "              },\n",
        "              # relative coords\n",
        "              \"vertices\": {\n",
        "                \"xmin\": result[\"left\"][i]/output[\"media\"][\"resolution\"][\"width\"],\n",
        "                \"ymin\": result[\"top\"][i]/output[\"media\"][\"resolution\"][\"height\"],\n",
        "                \"xmax\": (result[\"left\"][i] + result[\"width\"][i])/output[\"media\"][\"resolution\"][\"width\"],\n",
        "                \"ymax\": (result[\"top\"][i] + result[\"height\"][i])/output[\"media\"][\"resolution\"][\"height\"]\n",
        "                }\n",
        "          }\n",
        "          frame[\"boundingBoxes\"].append(box)\n",
        "      \n",
        "      #save frame if it had text\n",
        "      if len(frame[\"boundingBoxes\"]) > 0:\n",
        "        output[\"frames\"].append(frame)\n",
        "        #print(frame)\n",
        "  \n",
        "  with open(output_name, 'w') as outfile:\n",
        "    json.dump(output, outfile)\n",
        "  print(\"Finished \" + output_name + \" in \" + str(time.time()-script_start) + \"s\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJpXo1FEDvNT"
      },
      "source": [
        "## Visualize Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Rp2n1Abkgoe"
      },
      "source": [
        "# VISUALIZE RANDOM RESULT\n",
        "\n",
        "import random\n",
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib import patches, text\n",
        "import json\n",
        "\n",
        "# Sample to choose from\n",
        "sample = samples[0]#random.randrange(0,2)]\n",
        "\n",
        "# Open JSON file\n",
        "with open(sample[\"filename\"] + \"-ocr.json\", 'r') as infile:\n",
        "  data = json.load(infile)\n",
        "  \n",
        "# Select a random frame to show  \n",
        "n = random.randrange(0, len(data[\"frames\"]))\n",
        "frame = data[\"frames\"][n]\n",
        "print(frame)\n",
        "\n",
        "\n",
        "# Prep plot\n",
        "fig, ax = plt.subplots(figsize=(20,12)) \n",
        "\n",
        "\n",
        "# Capture video @ start time\n",
        "frame_time = frame[\"start\"] - sample[\"sample_start\"] # adjusting for the fact not all samples start @ 0\n",
        "vidcap = cv2.VideoCapture(\"../Clips/\"+sample[\"filename\"])\n",
        "print(frame_time)\n",
        "vidcap.set(cv2.CAP_PROP_POS_MSEC, frame_time*1000 + 240) # FIX: why is this 240 adjustment needed?\n",
        "success,image = vidcap.read()\n",
        "\n",
        "# Plot image\n",
        "if success:\n",
        "    ax.imshow(image[...,::-1]) # bgr to rgb\n",
        "\n",
        "    \n",
        "# Plot OCR results\n",
        "for box in frame[\"boundingBoxes\"]:\n",
        "  x = box[\"vertices\"][0][\"x\"]\n",
        "  y = box[\"vertices\"][0][\"y\"]\n",
        "  w = box[\"vertices\"][1][\"x\"] - x\n",
        "  h = box[\"vertices\"][1][\"y\"] - y\n",
        "  \n",
        "  rect = patches.Rectangle((x,y),w,h, linewidth=2, edgecolor='r', facecolor='none')\n",
        "  ax.add_patch(rect)\n",
        "  ax.text(x-2,y-2, box[\"text\"], fontsize=18, color='r')\n",
        "  \n",
        "  \n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}